# GitHub Copilot Instructions for Data Science Sandbox

## Project Overview

The Data Science Sandbox is a gamified learning platform that guides users through a structured data science journey from beginner to expert level. It combines interactive challenges, Jupyter notebooks, and a comprehensive dashboard to create an engaging educational experience.

## Code Style and Conventions

### Python Code Standards
- **Line Length**: Maximum 88 characters (Black formatter)
- **Import Organization**: Use isort with black profile
- **Type Hints**: Use type hints for all public functions and class methods
- **Docstrings**: Use Google-style docstrings for all classes and functions
- **Error Handling**: Use specific exception types, avoid bare except clauses
- **Logging**: Use the logging module instead of print statements for debugging

### File Organization
```
data-science-sandbox/
├── main.py                 # Main application entry point
├── config.py               # Configuration and game settings
├── sandbox/               # Core application modules
│   ├── core/             # Game engine and dashboard
│   ├── levels/           # Level-specific content
│   ├── achievements/     # Badge and achievement logic
│   └── utils/            # Utility functions
├── challenges/           # Coding challenges by level
├── notebooks/           # Interactive learning materials
├── data/                # Datasets and resources
├── docs/                # Documentation
├── tests/               # Unit and integration tests
└── scripts/             # Development and deployment scripts
```

## Development Guidelines

### When Adding New Features

1. **Game Engine Extensions**
   - Add new methods to `GameEngine` class for core functionality
   - Maintain backward compatibility with existing progress files
   - Update progress schema validation when adding new fields
   - Test with existing user data to ensure no data loss

2. **New Challenge Creation**
   - Follow the established challenge structure in markdown format
   - Include clear objectives, instructions, success criteria, and learning objectives
   - Provide complete, runnable code examples
   - Test code examples thoroughly before adding
   - Add corresponding entries to level configuration

3. **Dashboard Enhancements**
   - Use Streamlit best practices for UI components
   - Maintain responsive design for different screen sizes
   - Ensure accessibility with proper labels and descriptions
   - Test interactive elements thoroughly

4. **Data Pipeline Changes**
   - Validate all data transformations with sample datasets
   - Handle edge cases (empty data, missing columns, etc.)
   - Document data schema expectations
   - Provide fallback mechanisms for missing data

### Testing Requirements

- **Unit Tests**: All core functionality must have unit tests with >90% coverage
- **Integration Tests**: Test complete user workflows
- **Mock External Dependencies**: Use mocks for file I/O, network calls, etc.
- **Test Data**: Use fixtures for consistent test data across tests
- **Performance Tests**: For data processing functions handling large datasets

### Code Patterns to Follow

1. **Configuration Management**
```python
# Good - Use centralized config
from config import LEVELS, BADGES, BASE_DIR

# Avoid - Hardcoded values
MAX_LEVEL = 6  # Instead use LEVELS configuration
```

2. **Error Handling**
```python
# Good - Specific exceptions with context
def load_progress(self, file_path: str) -> Dict[str, Any]:
    try:
        with open(file_path, 'r') as f:
            return json.load(f)
    except FileNotFoundError:
        logger.info(f"Progress file not found: {file_path}, creating new")
        return self._create_new_progress()
    except json.JSONDecodeError as e:
        logger.error(f"Invalid JSON in progress file: {e}")
        raise ProgressFileCorruptedError(f"Cannot parse progress file: {e}")

# Avoid - Bare except or generic exceptions
try:
    with open(file_path, 'r') as f:
        return json.load(f)
except:  # Too broad
    return {}  # Loss of information
```

3. **Data Processing**
```python
# Good - Defensive programming with validation
def process_challenge_data(self, data: pd.DataFrame) -> pd.DataFrame:
    if data.empty:
        raise ValueError("Cannot process empty dataset")
    
    required_columns = ['id', 'timestamp', 'value']
    missing_columns = set(required_columns) - set(data.columns)
    if missing_columns:
        raise ValueError(f"Missing required columns: {missing_columns}")
    
    # Process data...
    return cleaned_data
```

4. **Progress Tracking**
```python
# Good - Atomic operations with rollback capability
def complete_challenge(self, challenge_id: str, score: int) -> bool:
    old_progress = self.progress.copy()
    try:
        self.progress['challenges_completed'].append(challenge_id)
        self.progress['experience_points'] += self._calculate_xp(score)
        self._check_level_completion()
        self.save_progress()
        return True
    except Exception as e:
        self.progress = old_progress  # Rollback
        logger.error(f"Failed to complete challenge {challenge_id}: {e}")
        return False
```

## Content Creation Guidelines

### Challenge Design Principles

1. **Progressive Difficulty**: Each level should build upon previous concepts
2. **Practical Applications**: Use realistic datasets and business scenarios
3. **Clear Learning Objectives**: Explicitly state what skills will be developed
4. **Complete Examples**: All code should run without modification
5. **Visual Feedback**: Include plots and visualizations where appropriate

### Challenge Structure Template
```markdown
# Level X: [Level Name]

## Challenge Y: [Challenge Title]

Brief introduction that motivates the challenge and connects to real-world applications.

### Objective
Clear, specific statement of what the user will accomplish.

### Instructions

```python
# Complete, runnable code with:
# 1. All necessary imports
# 2. Data loading/creation
# 3. Step-by-step tasks with comments
# 4. Expected outputs
```

### Success Criteria
- Specific, measurable outcomes
- Technical skills demonstrated
- Concepts mastered

### Learning Objectives
- Skills developed in this challenge
- Connection to broader data science concepts
- Preparation for next challenges

### Next Steps (optional)
Hints about upcoming challenges or advanced topics

---

*Pro tip: Practical advice or best practice*
```

### Notebook Guidelines

1. **Cell Organization**: One concept per cell, clear markdown explanations
2. **Interactive Elements**: Use widgets where appropriate for exploration
3. **Error Handling**: Graceful handling of common user errors
4. **Data Sources**: Include both sample and real-world datasets
5. **Checkpoints**: Save/load capabilities for long notebooks

## Technical Architecture

### Core Components

1. **GameEngine**: Central state management and progress tracking
2. **Dashboard**: Streamlit-based web interface
3. **Challenge System**: Markdown-based challenge definitions
4. **Progress Persistence**: JSON-based user progress storage
5. **Data Pipeline**: Pandas-based data processing and validation

### Extension Points

- **Achievement System**: `sandbox/achievements/` for custom badges
- **Level Definitions**: `config.py` LEVELS dictionary
- **Challenge Categories**: `config.py` CATEGORIES for organization
- **Custom Visualizations**: Dashboard components in `sandbox/core/dashboard.py`

## Performance Considerations

### Data Processing
- Use pandas vectorized operations instead of loops
- Implement lazy loading for large datasets
- Cache expensive computations
- Provide progress indicators for long operations

### Memory Management
- Clear large DataFrames when no longer needed
- Use generators for processing large files
- Monitor memory usage in interactive environments

### User Experience
- Provide immediate feedback for user actions
- Handle long-running operations asynchronously
- Graceful degradation for missing dependencies

## Security Guidelines

### Data Handling
- Validate all user inputs
- Sanitize file paths to prevent directory traversal
- Use safe methods for dynamic code execution in challenges
- Never store sensitive information in progress files

### Dependencies
- Regularly update dependencies for security patches
- Use virtual environments for isolation
- Pin dependency versions for reproducibility

## Deployment Considerations

### Environment Setup
- Document all system requirements
- Provide automated setup scripts
- Support multiple Python versions (3.8+)
- Include Docker configuration for containerized deployment

### Scaling Considerations
- Design for multi-user environments
- Separate user data from application code
- Consider database backends for large user bases
- Plan for distributed file storage

## Common Patterns and Anti-Patterns

### ✅ Good Patterns

1. **Consistent Error Messages**: Use a standardized format
2. **Comprehensive Logging**: Log all important state changes
3. **Modular Design**: Keep components loosely coupled
4. **Configuration-Driven**: Avoid hardcoded values
5. **Test Coverage**: Write tests before implementing features

### ❌ Anti-Patterns to Avoid

1. **Global State Mutation**: Always pass state explicitly
2. **Silent Failures**: Always handle and report errors
3. **Tight Coupling**: Avoid direct dependencies between unrelated modules
4. **Magic Numbers**: Use named constants from configuration
5. **Untested Code**: Never merge untested functionality

## AI Assistant Guidelines

When helping with this project:

1. **Understand Context**: Always consider the educational purpose
2. **Maintain Consistency**: Follow established patterns and conventions
3. **Progressive Complexity**: Ensure new content fits the learning progression
4. **Complete Solutions**: Provide fully working examples
5. **Educational Value**: Focus on teaching concepts, not just solving problems

### Code Generation Preferences

- Prioritize readability and educational value over performance optimization
- Include comprehensive comments explaining complex concepts
- Use descriptive variable names that help understanding
- Provide error handling that teaches good practices
- Include visualization and output that demonstrates results

### When Suggesting Improvements

- Explain the reasoning behind suggestions
- Consider the impact on existing user progress
- Provide migration strategies for breaking changes
- Maintain backward compatibility when possible
- Document all changes thoroughly

## Future Enhancement Ideas

- Multi-language support for international users
- Advanced ML topics (deep learning, NLP, computer vision)
- Real-time collaboration features
- Integration with external data sources (APIs, databases)
- Advanced analytics for learning path optimization
- Competitive elements (leaderboards, team challenges)
- Industry-specific specialization tracks
- Integration with popular data science platforms

Remember: This is an educational platform first. Every technical decision should be evaluated based on its educational value and learning experience enhancement.